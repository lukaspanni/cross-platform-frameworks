\chapter{Implementierung und Evaluation}
\label{ch:evaluation}

Zunächst beschreibt \autoref{sec:implementierung} die Implementierung des Prototyps zur Videoaufzeichnung mit den entsprechenden Frameworks und die Bewertung der Grundfunktionalität des jeweiligen Prototyps.
Alle Prototypen stehen unter \url{https://github.com/lukaspanni/cross-platform-evaluation} zur Verfügung.
Dabei wird erläutert, wie die einzelnen Komponenten des Prototyps implementiert werden und welche zusätzlichen Komponenten eingesetzt werden müssen, um die geforderte Funktionalität umzusetzen.
Die Frameworks verwenden verschiedene Bezeichnungen für eingebundene Komponenten von Drittanbietern.
Zur einheitlichen Beschreibung werden diese in den folgenden Abschnitten jeweils als Plugins bezeichnet.
Außerdem wird jeweils beschrieben, inwiefern die geforderte Grundfunktionalität umgesetzt werden kann und welche Einschränkungen, zum Beispiel bei der Einstellung der Parameter, existieren.
In \autoref{sec:evaluation_allgemein} werden anschließend die Ergebnisse der allgemeinen Evaluationen nach den, in \autoref{sec:kriterien} beschriebenen Kriterien, zusammengefasst.

Für die Evaluierung werden die Prototypen jeweils auf einem Android- und einem iOS-Gerät getestet.
Konkret werden ein Google Pixel 4a 5G mit Android 13 und ein iPhone XR mit iOS 16.1.1 verwendet. 

\section{Implementierung und Evaluation der Grundfunktionalität}
\label{sec:implementierung}

Insgesamt ist festzustellen, dass die Grundfunktionalität der Aufzeichnung von Videos mit allen untersuchten Frameworks mit vorhandenen Plugins umgesetzt werden kann.
Auch der Zugriff auf den Gerätespeicher zur Speicherung der Videos ist in allen Frameworks möglich.
Dabei ist jedoch aufgefallen, dass kein Framework plattformübergreifende Speicherpfade unterstützt.
Stattdessen muss für jede Plattform ein passender Pfad, angepasst an die jeweilige Dateisystemstruktur, erzeugt werden.
Erste Unterschiede zeigen sich bei der Wiedergabe aufgezeichneter Videos.
Diese ist in Ionic mit Cordova mit allen getesteten Plugins nicht möglich.

Welche Komponenten verwendet wurden, welche Probleme aufgetreten sind und welche Einstellmöglichkeiten für die Parameter bestehen ist in den Abschnitten \ref{sec:evaluation_flutter} bis \ref{sec:evaluation_reactnative} beschrieben.

\subsection{Implementierung mit Flutter}
\label{sec:evaluation_flutter}

Flutter bringt verschiedene Abstraktionen für den Zugriff auf native Funktionen standardmäßig mit.
Für den Zugriff auf Kamerafunktionen muss jedoch ein Plugin genutzt werden.
Plugins für Flutter und Dart werden in einem öffentlichen Repository unter \url{https://pub.dev} zur Verfügung gestellt.
Mit dem Plugin \textit{camera} \cite{Dart_Camera} ist ein, vom Flutter-Team gepflegtes, offizielles Plugin verfügbar. 
Über dieses Plugin ist die Aufzeichnung von Videos unter Android und iOS möglich.
Außerdem können verschiedene Parameter eingestellt werden.
Für die Speicherung ist kein zusätzliches Plugin notwendig, der Zugriff auf Gerätespeicher ist in Flutter bereits integriert.
Zur Wiedergabe der Videos wird das offizielle Video-Player-Plugin verwendet \cite{Dart_Video}.

Die erforderlichen Anforderungen sowie die Wiedergabe von Videos können somit mit Flutter vollständig umgesetzt werden.
Allerdings gibt es einige Einschränkungen bei den einstellbaren Parametern.
So sind weder Belichtungszeit noch ISO-Wert einstellbar, für die Belichtung kann nur ein Offset für die automatische Belichtungssteuerung vorgegeben werden.
Zudem kann die Aktualisierung der automatischen Belichtungssteuerung gestoppt werden, die letzte automatische Einstellung bleibt dabei erhalten.
Diese Funktion ist auch als \ac{AEL} bekannt.
Der Fokus kann ebenfalls nicht komplett manuell gewählt werden, stattdessen lässt sich ein Punkt des Videos wählen, welcher vom Autofokussystem als Ausgangspunkt verwendet wird.
Für das Bildformat stehen bis zu fünf verschiedene Voreinstellungen zur Verfügung, wobei die Verfügbarkeit vom verwendeten Gerät abhängt.
Weißabgleich, Videocodec und Bildrate lassen sich ebenfalls nicht einstellen.
Außerdem konnte nicht jeder verfügbare Sensor des Android-Testsmartphones ausgewählt werden.
Da das iOS-Testgerät nur jeweils einen Sensor für die Front- und Rückkamera besitzt, konnte diese Einschränkung unter iOS nicht getestet werden.


\subsection{Implementierung mit Ionic und Cordova}
\label{sec:evaluation_ionic}

Allgemein erlaubt Cordova den Zugriff auf native Funktionen, wie die Videoaufzeichnung nur über Plugins.
Erste Quelle für bestehende Plugins ist bei Verwendung von Ionic als UI-Toolkit die Sammlung offiziell unterstützter und getesteter Plugins, die unter \url{https://ionicframework.com/docs/native/} bereitsteht.
Hier konnten drei Plugins identifiziert werden, welche den Zugriff auf Kamerafunktionen ermöglichen.
Das naheliegende Plugin \textit{cordova-plugin-camera} erlaubt nur die Aufzeichnung von Bildern \cite{Cordova_Camera}.
Das Plugin \textit{cordova-plugin-camera-preview} ermöglicht zwar die Aufzeichnung von Videos, jedoch ist diese Funktion nur auf Android-Geräten verfügbar \cite{Cordova_CameraPreview}.
Lediglich das Plugin \textit{cordova-plugin-media-capture} erlaubt die Aufzeichnung von Videos auf allen Plattformen \cite{Cordova_MediaCapture}.
Jedoch verwendet dieses Plugin eine vom Betriebssystem bereitgestellte Aufzeichnungsfunktion, sodass aus der App heraus nur das Videoaufzeichnungsfenster geöffnet werden kann.
Außerdem sind deshalb keinerlei Einstellungen der in \autoref{tab:parameter_support} aufgeführten Parameter möglich.
Auch außerhalb der offiziellen Sammlung von verifizierten Plugins konnten keine Plugins identifiziert werden, welche die Einstellung einiger Parameter unterstützen.

Die Speicherung aufgezeichneter Videos erfolgt ohne zu erkennende Einschränkungen über das offizielle Plugin \textit{cordova-plugin-file} \cite{Cordova_File}.
Die Wiedergabe der Videos hingegen konnte weder über das HTML-Video Element noch durch ein Plugin realisiert werden. 

Damit sind die erforderlichen Anforderungen zwar umgesetzt, jedoch werden keine der optionalen Anforderungen erfüllt.
Um die optionalen Anforderungen umzusetzen, müssten spezifische Plugins implementiert werden.
Dementsprechend ist die Implementierung einer Videoaufzeichnungsanwendung mit Ionic und Cordova nur stark eingeschränkt möglich.


\subsection{Implementierung mit Xamarin}
\label{sec:evaluation_xamarin}

Da Xamarin prinzipiell die Nutzung der nativen \acp{API} unterstützt, sind theoretisch alle Kamerafunktionen nutzbar.
Allerdings sollen im Rahmen dieser Arbeit nur die vorhandenen plattformübergreifenden Abstraktionen des Frameworks genutzt werden.
Standardmäßig werden Open-Source Komponenten für .NET-Anwendungen über den Paketmanager NuGet verwaltet und im Repository \url{https://nuget.org} bereitgestellt.
Dort sind auch die offiziellen Xamarin-Bibliotheken verfügbar.
Die offizielle Bibliothek \textit{Xamarin.Essentials} ermöglicht neben der Nutzung weiterer nativer Funktionen auch den Zugriff auf verschiedene Kamerafunktionen.
Die Kamera kann über eine stark vereinfachte \ac{API} der statischen Klasse \textit{MediaPicker} genutzt werden \cite{Xamarin_MediaPicker}.
Wie in der Implementierung mit Cordvoa, wird auch hier die Aufzeichnung von Videos über die vom Betriebssystem bereitgestellte Aufzeichnungsfunktion realisiert.
Deshalb ist auch bei Xamarin-Anwendungen die Aufzeichnung von Videos zwar möglich, jedoch können keine Parameter aus der Anwendung heraus angepasst werden.
Der Zugriff auf den Gerätespeicher ist wie bei Flutter ohne zusätzliche Abhängigkeiten möglich.
Die Wiedergabe der Videos ist über ein entsprechendes \ac{UI}-Element der offiziellen Bibliothek \textit{XamarinCommunityToolkit} \cite{Xamarin_CommunityToolkit} ohne Einschränkungen möglich.

Ohne Nutzung nativer \acp{API} können mit Xamarin nur die Anforderungen zur Aufzeichnung und Speicherung sowie zur Wiedergabe von Videos erfüllt werden.
Die optionale Einstellbarkeit der Parameter lässt sich mit den vorhandenen Bibliotheken nicht umsetzen.


\subsection{Implementierung mit React Native}
\label{sec:evaluation_reactnative}

Für React Native existiert keine eigenständige Quelle für Plugins.
Stattdessen wird der JavaScript-Paketmanager \textit{npm} und die Registry unter \url{https://npmjs.com} verwendet, um Plugins zu verwalten.
Für die Videoaufzeichnung mit React Native konnten zwei geeignete Plugins identifiziert werden.
Da das Plugin \textit{react-native-vision-camera} \cite{Vision_Camera} bei der Einstellung von Parametern mehr Flexibilität bietet als das Plugin \textit{expo-camera} \cite{Expo_Camera}, wurde dieses für die prototypische Implementierung ausgewählt.
Zur Speicherung und Wiedergabe der Videos müssen zusätzlich \textit{react-native-fs} \cite{ReactNative_FileSystem} respektive \textit{react-native-video} \cite{ReactNative_Video} eingebunden werden.

Das Plugin \textit{react-native-vision-camera} verwendet die neue Architektur von React Native, wie in \autoref{sec:frameorks_reactnative} beschrieben.
Die neue Architektur ist bei neuen Projekten standardmäßig aktiviert und verwendet ohne weitere Konfiguration die JavaScript Engine Hermes.
Diese Einstellungen werden für die Implementierung beibehalten.

Die erforderlichen Anforderungen und die Wiedergabe von Videos können mit React Native ohne Einschränkungen umgesetzt werden.
Bei der Einstellbarkeit der Parameter gibt es im Vergleich mit den anderen Frameworks zudem weniger Einschränkungen.
So lässt sich beispielsweise der Sensor ohne Einschränkungen frei wählen.
Abhängig von den Fähigkeiten des Sensors werden die verfügbaren Einstellungen durch das Framework eingeschränkt.
Allgemein lassen sich die möglichen Einstellungen nach der Wahl des Sensors über das Plugin abfragen und können dem Nutzer angezeigt werden.
Verschiedene Sensoren unterstützen dabei unterschiedliche Kombinationen von Einstellungen, welche als Format bezeichnet werden.
Ein Format definiert dabei insbesondere das Bildformat und den verwendeten Farbraum.
Abhängig vom Format ist auch der Bereich, in welchem die Bildrate eingestellt werden kann.
Bei den Testgeräten war die Einstellung jeweils im Bereich von einem bis 60 Bildern pro Sekunde möglich.
Weiterhin kann der Fokus in ähnlicher Art und Weise wie bei Flutter gesetzt werden.
Im Vergleich zu Flutter kann jedoch die Belichtung nicht eingestellt werden.
Das Plugin erlaubt unter iOS zudem die Wahl des Videocodecs.
Dabei sind verschiedene Einschränkungen aufgefallen.
Beim Testgerät waren nur die Codecs H.264, \ac{HEVC} (H.265) und JPEG verfügbar.
Weiterhin war die Auswahl nur bei Auflösungen unter 3840x2160 möglich.
Diese und alle höheren Auflösungen unterstützen nur den Codec \ac{HEVC}.
Laut Dokumentation kann das Plugin auch den Apple-eigenen Codec \textit{ProRes} verwenden, der allerdings nur auf den jeweiligen Pro-Modellen der iPhones 13 und 14 verfügbar ist \cite{Prores_iPhone13}.
Das Plugin bietet keine Möglichkeit die Belichtungsparameter ISO und Belichtungszeit einzustellen.

\subsection{Zusammenfassung Evaluation Grundfunktionalität}

Die geforderten Grundfunktionalitäten der Aufzeichnung und Speicherung können mit allen Frameworks umgesetzt werden.
Die Wiedergabe ist mit Ausnahme von Ionic mit Cordova ebenfalls möglich.
Bei der Einstellbarkeit der Parameter gibt es jedoch Unterschiede zwischen den Frameworks.
Insbesondere sind bei Xamarin und Ionic mit Cordova aufgrund der Nutzung der Standardanwendung zur Videoaufzeichnung keine Einstellungen der Parameter möglich.
Da Flutter und React Native nicht auf die Standardanwendung angewiesen sind, sondern direkt \acp{API} des Betriebssystems nutzen sind hier mehr Einstellungen möglich.
\autoref{tab:parameter_support_evaluation} fasst die Einstellbarkeit der Parameter für Flutter und React Native zusammen.
\begin{table}[H]
  \begin{tabularx}{\textwidth}{ |l|X|X| }
      \hline
      \textbf{Parameter} & \textbf{Flutter} & \textbf{React Native}  \\
      \Xhline{0.5mm}
      \textbf{Belichtungszeit} & \xmark & \xmark \\
      \hline
      \textbf{Sensorempfindlichkeit (ISO)} & \xmark & Wahl von Format mit unterschiedlichen Minimal- \& Maximalwerten \\
      \hline
      \textbf{Blende} & Über Sensor-Auswahl (Einschränkungen unter Android) & Über Sensor-Auswahl \\
      \hline
      \textbf{Brennweite} & Über Sensor-Auswahl (Einschränkungen unter Android) & Über Sensor-Auswahl \\
      \hline
      \textbf{Fokus} & Ausgangspunkt für Autofokussystem wählbar & Ausgangspunkt für Autofokussystem wählbar \\
      \hline
      \textbf{Weißabgleich} & \xmark & \xmark \\
      \hline
      \textbf{Bildrate} & \xmark & Bereich abhängig von Sensor und Format (Auflösung \& Farbraum) \\
      \hline
      \textbf{Bildformat} & Wahl aus maximal fünf Voreinstellungen & Wahl aus vom Gerät bereitgestellten Formaten (in Tests jeweils mehr Formate als Flutter) \\
      \hline
      \textbf{Kompressionsverfahren/Codec} & \xmark & nur unter iOS und abhängig von Auflösung \\
      \hline
  \end{tabularx}
  \caption{Einstellbarkeit der Parameter durch die Plugins für Flutter und React Native.}
  \label{tab:parameter_support_evaluation}
\end{table}






\section{Vergleich allgemeiner Kriterien}
\label{sec:evaluation_allgemein}

Im Folgenden werden die Ergebnisse der Evaluierung der Frameworks hinsichtlich der allgemeinen Kriterien zusammengefasst.
Dabei werden die Größe eines Release-Builds, die Zeit von Start der App bis zur vollständigen Funktionsfähigkeit und die zusätzlich benötigte Zeit für den definierten Ende-zu-Ende-Test betrachtet.

Die Hardware der Testgeräte ist sehr unterschiedlich.
Zum Beispiel ist das Android-Testgerät mit der doppelten Menge Arbeitsspeicher ausgestattet, verwendet jedoch einen, in synthetischen Benchmarks, langsameren Prozessor \cite{Comparison_Phones}.
Deshalb sind die Ergebnisse nur eingeschränkt Plattformübergreifend vergleichbar.
Zur besseren Vergleichbarkeit werden zusätzlich die auf die Mittelwerte der jeweiligen Plattformen normalisierten Werte betrachtet.


\subsection{Größe eines Release-Builds}

Die jeweilige Größe eines Release-Builds der Prototypen in Mega-Byte sind in \autoref{fig:app_size} dargestellt.
Wie erwartet gibt es große Unterschiede abhängig vom verwendeten Framework.
Weiterhin fällt auf, dass iOS-Apps durchschnittlich größer sind als Android-Apps.
\begin{figure}[ht]
  \centering 
  \includegraphics[trim=1.5cm 4.5cm 1.5cm 4.5cm, clip, width=0.9\textwidth]{app_size.pdf}
  \caption{Vergleich der Größe eines Release-Builds abhängig von Framework und Betriebssystem.}
  \label{fig:app_size}
\end{figure}

Unter Android sind die Release-Builds, welche mit Ionic und Cordova beziehungsweise Xamarin erstellt wurden, mit 5,9 MB und 10,9 MB vergleichsweise klein.
Dies kann auf die Verwendung der vom Betriebssystem bereitgestellten Videoaufzeichnungsanwendung zurückgeführt werden.
Die Größe der App lässt sich reduzieren, indem die vom Betriebssystem bereitgestellte Anwendung aufgerufen wird, anstatt eine eigene Implementierung mitzuliefern.
Die gleiche Argumentation gilt für die Varianten für iOS.
Auch unter iOS ist die mit Ionic und Cordova erstellte App kleiner als die Apps der anderen Frameworks.
Die \ac{IPA}-Datei von Xamarin-Anwendungen ist jedoch, wie durch die \ac{AOT}-Kompilation erwartet, deutlich größer als die entsprechende \ac{AAB}-Datei


Die mit Flutter und React Native erstellten Apps sind unter Android mit 18,1 MB und 21,7 MB deutlich größer als die mit Ionic und Cordova und Xamarin implementierten Anwendungen.
Da diese nicht auf die Standardanwendung des Betriebssystems zurückgreifen, muss die Funktionalität der Videoaufzeichnung mitgeliefert werden.
Weiterhin liefern sowohl React Native als auch Flutter standardmäßig verschiedene sonstige Abhängigkeiten mit, welche die Größe der App erhöhen.
Wie bei der Erläuterung der Frameworks in \autoref{sec:frameworks_flutter} beschrieben wird mit jeder Flutter-Anwendung eine Version der Skia Engine mitgeliefert.
Bei React Native muss jeweils eine JavaScript Engine mitgeliefert werden, für den Prototyp wird die Standardeinstellung nicht verändert, wodurch die für React Native optimierte Hermes Engine verwendet wird.

Die mit React Native erstellte App für iOS ist ein Ausreißer.
Mit 157,6 MB fällt die App deutlich größer aus als alle anderen Implementierungen.
Zwar ist die App unter Android ebenfalls vergleichsweise groß, jedoch fällt die Abweichung zu den anderen Frameworks weniger stark aus.
Sehr große \ac{IPA}-Dateien wurden bei der Verwendung der Hermes Engine bereits mehrfach beobachtet \cite{Hermes_appsize,Hermes_appsize_2}.
Wird anstatt Hermes, die von iOS bereitgestellte JavaScript Core Engine verwendet, reduziert sich die App-Größe deutlich auf 3,1 MB, wie in \autoref{fig:reactnative_appsize_ios} zu sehen ist.
Unter Android trägt die Hermes Engine stattdessen zu einer kleineren App-Größe bei.
Ein Build mit der JavaScript Core Engine ist unter Android mit 51,9 MB deutlich größer als der Build mit der Hermes Engine mit 21,7 MB.
Da die Hermes Engine bei neuen React Native Projekten standardmäßig aktiviert ist, wird diese Variante für die Evaluation verwendet.
Außerdem ist anzumerken, dass die \ac{IPA}-Größe nicht repräsentativ für die Größe der App ist, welche über den App-Store verteilt wird.
Dies liegt daran, dass die \ac{IPA}-Datei verschiedene Varianten des Codes für verschiedene Geräte enthält und die finale, optimierte Version der App erst beim Upload zum App-Store erstellt wird \cite{IPA_Size}.
Da jedoch keine Methode bekannt ist, mit der die finale App-Größe bestimmt werden kann, ohne ein kostenpflichtiges Entwicklerkonto bei Apple zu besitzen, muss die \ac{IPA}-Größe zur Bewertung verwendet werden.
Im realen Einsatz, könnten Entwickler entscheiden, unter Android und iOS verschiedene Engines einzusetzen, um die App-Größe jeweils zu minimieren.

\begin{figure}[ht]
  \centering 
  \includegraphics[clip, width=0.9\textwidth]{reactnative_appsize_ios}
   \caption{Vergleich der App-Größe einer React Native-Anwendung für iOS mit und ohne Verwendung der Hermes Engine.}
  \label{fig:reactnative_appsize_ios}
\end{figure}


\subsection{Dauer bis zur vollständigen Funktionsfähigkeit}

Wie lange die jeweiligen Prototypen zwischen Start und vollständiger Funktionsfähigkeit benötigen, ist in \autoref{fig:launch_time} dargestellt.
Jeder Wert ist dabei als Mittelwert aus fünf Messungen angegeben.
Zur Messung der Kaltstartzeiten wird sichergestellt, dass nach jeder Messung die App komplett beendet wird.

Unter Android sind alle Startzeiten konsistent zwischen 50 und 64 \% schneller als unter iOS.
Dies kann vermutlich auf Hardwareunterschiede und Unterschiede im Betriebssystem zurückgeführt werden.
Insbesondere die große Differenz der verfügbaren Arbeitsspeichermenge könnte hier eine Rolle spielen.
Welcher Anteil der Unterschiede auf die Hardware und welcher auf das Betriebssystem zurückzuführen ist, kann jedoch mangels identischer Hardware nicht eindeutig bestimmt werden.

Die auf die durchschnittliche Startzeit auf dem jeweiligen Testgerät normalisierten Zeiten sind in \autoref{fig:launch_time_normalized} dargestellt.
Hier fallen kaum Unterschiede zwischen den Plattformen auf, was die Vermutung verstärkt, dass die Unterschiede auf grundsätzliche Unterschiede der Hardware und der Betriebssysteme zurückzuführen sind.
\begin{figure}[ht]
  \centering 
  \includegraphics[trim=1.8cm 4.5cm 1.8cm 4.5cm, clip, width=0.9\textwidth]{launch_time.pdf}
  \caption{Vergleich der Zeit bis zur vollständigen Funktionsfähigkeit des Prototyps abhängig von Framework und Betriebssystem.}
  \label{fig:launch_time}
\end{figure}


Für die Messung der Startzeit kann bei Flutter und Xamarin auf die \ac{TTFD} zurückgegriffen werden.
Bei beiden Frameworks ist die vollständige Funktionsfähigkeit der App zu diesem Zeitpunkt bereits erreicht.
Andererseits kann die \ac{TTFD} bei React Native und Ionic mit Cordova nicht herangezogen werden, da diese Frameworks die Initialisierung nicht komplett abgeschlossen haben, wenn das erste Frame gezeichnet wird.
Bei Ionic mit Cordova misst die \ac{TTFD} nur die Zeit bis zur Anzeige der Wrapper-Anwendung.
Die folgende Initialisierung der WebView mit der eigentlichen Anwendung in JavaScript wird nicht berücksichtigt.
Deshalb wird stattdessen die Zeit bis zum Event \texttt{Platform.ready} zur Messung verwendet.
Das Event wird vom Framework ausgelöst, sobald die Anwendung komplett bereit ist und der Benutzer mit den Steuerelementen interagieren kann.
Auch bei React Native ist die \ac{TTFD} nicht aussagekräftig, da auch hier die Initialisierung der Anwendung nicht mit der Initialisierung des nativen Codes abgeschlossen ist.
Ab dem ersten Aufruf der \texttt{render}-Methode kann beliebiger Code ausgeführt werden, weshalb dieser Zeitpunkt zur Messung herangezogen wird.

Von allen untersuchten Frameworks starten die Prototypen mit Flutter und React Native am schnellsten.
Unter Android ist Flutter dabei etwas schneller als React Native, unter iOS ist es umgekehrt.
Der absolute Unterschied ist jedoch mit 22 ms respektive 21 ms sehr gering.

\begin{figure}[ht]
  \centering 
  \includegraphics[trim=1.8cm 4.5cm 1.8cm 4.5cm, clip, width=0.9\textwidth]{launch_time_normalized.pdf}
  \caption{Vergleich der Zeit bis zur vollständigen Funktionsfähigkeit des Prototyps abhängig von Framework und Betriebssystem, normalisiert auf die durchschnittliche Startzeit des Geräts.}
  \label{fig:launch_time_normalized}
\end{figure}
Die Xamarin-Anwendung und die Anwendung, welche mit Ionic und Cordova implementiert ist, benötigen deutlich länger, bis die vollständige Funktionsfähigkeit erreicht ist.
Obwohl sowohl bei Ionic mit Cordova als auch bei React Native die Logik in JavaScript implementiert ist, ist die Startzeit der Cordova-Anwendung mehr als viermal länger.
Daraus lässt sich schließen, dass die Verwendung von nativen Steuerelementen anstelle einer WebView einen positiven Einfluss auf die Startzeit hat.
Allerdings nutzt React Native auch eine für das Framework optimierte JavaScript Engine, was vermutlich ebenfalls einen positiven Einfluss auf die Startzeit hat.

Für Xamarin-Anwendungen wurde aufgrund der \ac{JIT}-Kompilation unter Android eine deutlich längere Startzeit als unter iOS erwartet.
Mit 166 \% der durchschnittlichen Startzeit unter iOS und 152 \% der durchschnittlichen Startzeit unter Android fällt der Unterschied zwischen den beiden Plattformen jedoch weniger stark aus als angenommen.
Ein Grund dafür konnte nicht identifiziert werden.
Vermutlich ist der Einfluss der \ac{JIT}-Kompilation bei Anwendungen mit wenig Code, wie es bei dem Prototyp für ein einzelnes Feature der Fall ist, nur gering.

\subsection{Ende-zu-Ende-Test}

Die automatisierte Aufzeichnung und Speicherung eines Videos für den Ende-zu-Ende-Test ist nur bei Flutter- und React Native-Anwendungen möglich.
Sowohl bei Ionic mit Cordova als auch bei Xamarin kann die Aufzeichnung von Videos aufgrund der Verwendung der Standardanwendung zur Videoaufzeichnung nicht automatisiert werden.
Die in \autoref{fig:testcase} aufgeführten Zeiten, stellen jeweils einen Mittelwert aus fünf Messungen dar.
Für die Messung wurden dabei die von den Frameworks bereitgestellten Funktionen zur Zeitmessung verwendet.
Vom gemessenen Wert wird zusätzlich die Dauer des aufgezeichneten Videos abgezogen, da diese in allen Tests gleich gesetzt wurde.

\begin{figure}[ht]
  \centering 
  \includegraphics[trim=1.8cm 4.5cm 1.8cm 4.5cm, clip, width=0.9\textwidth]{testcase.pdf}
  \caption{Vergleich der für die Aufzeichnung und Speicherung von zehn Sekunden Video zusätzlich benötigten Zeit abhängig von Framework und Betriebssystem.}
  \label{fig:testcase}
\end{figure}

Direkt auffällig ist, dass die zusätzlich benötigte Zeit unter iOS deutlich geringer ausfällt als unter Android.
Dies lässt sich vermutlich auf Unterschiede der verwendeten Hardware und grundsätzliche Unterschiede zwischen den Betriebssystemen zurückführen.
Es wird angenommen, dass der Overhead für den Zugriff auf Kamerafunktionen und den Gerätespeicher unter iOS geringer ist als unter Android.
Außerdem kann der performantere Prozessor des iOS-Testgeräts, insbesondere bei rechenintensiver Codierung des Videos, zu einer schnelleren Ausführung beitragen.

\begin{figure}[ht]
  \centering 
  \includegraphics[trim=1.8cm 4.5cm 1.8cm 4.5cm, clip, width=0.9\textwidth]{testcase_normalized.pdf}
  \caption{Vergleich der für die Aufzeichnung und Speicherung von zehn Sekunden Video zusätzlich benötigten Zeit, normalisiert auf die durchschnittliche Zeit.}
  \label{fig:testcase_normalized}
\end{figure}
Die normalisierten Werte in \autoref{fig:testcase_normalized} zeigen, dass der Unterschied zwischen den Frameworks plattformunabhängig nahezu identisch ausfällt.
In beiden Fällen ist der automatisierte Testfall in der Flutter-Anwendung mehr als viermal langsamer als in der mit React Native implementierten Anwendung.
Dies lässt sich mit fundamentalen Unterschieden zwischen den Frameworks erklären.
Beide Frameworks wählen zum Zugriff auf native Funktionen einen unterschiedlichen Ansatz, der nach den hier vorgestellten Ergebnissen große Auswirkungen auf den Overhead beim Zugriff auf Kamerafunktionen und den Gerätespeicher hat.

Das eingesetzte React Native Plugin verwendet die neue, in \autoref{sec:frameorks_reactnative} beschriebene Architektur.
Damit können plattformspezifische Host-Objects direkt aus JavaScript aufgerufen werden.
Dadurch entfällt insbesondere der Aufwand für Serialisierung und Deserialisierung von Nachrichten, welche zwischen dem nativen Teil und dem plattformübergreifenden Teil der Anwendung ausgetauscht werden.
Im Vergleich verwenden sowohl die alte Architektur von React Native als auch Flutter eine Nachrichtenbasierte Kommunikation.
Somit erfordert jeder Funktionsaufruf zwei zusätzliche Nachrichten, welche jeweils eine Serialisierung und Deserialisierung erfordern.
Damit ist die Kommunikation zwischen plattformunabhängigem Anteil und plattformspezifischem Anteil der jeweiligen App mit React Native deutliche effizienter als bei Flutter.
Da die Plugins tatsächlich getätigte native Aufrufe und deren Anzahl verbergen, ist aus der Anwendung heraus nicht ersichtlich, wie viele native Funktionsaufrufe durch den Aufruf einer Plugin-Funktion ausgelöst werden.
Somit können auch Unterschiede in den Plugins Grund für die unterschiedlichen Ergebnisse sein.
Bei den beobachteten sehr großen Unterschieden ist jedoch davon auszugehen, dass die Effizienz der Kommunikation die Hauptursache für die Abweichungen ist.



\subsection{Zusammenfassung Evaluation allgemeine Kriterien}

Mit einer kurzen Startzeit, der besten Performance beim Ende-zu-Ende-Test und der größten Freiheit bei der Einstellung der Video-Parameter ist React Native als am besten geeignetes Framework für die Entwicklung einer Videoaufzeichnungsanwendung für Android und iOS zu bewerten.
Zudem lässt sich das Problem der App-Größe unter iOS durch die Nutzung der JavaScriptCore Engine umgehen.
Einzig Flutter kann ebenfalls für die Umsetzung von Videoaufzeichnung mit Cross-Plattform Frameworks empfohlen werden.
Die Startzeiten sind sehr ähnlich zu React Native, allerdings fällt die Performance im Ende-zu-Ende-Test deutlich schlechter aus und weniger Parameter können eingestellt werden.
Weiterhin ist die App-Größe unter iOS deutlich und unter Android geringfügig kleiner.
Jedoch muss beachtet werden, dass die stark gestiegene App-Größe für React Native unter iOS auf einen Fehler im Zusammenspiel mit der Hermes Engine zurückzuführen ist.

Ionic mit Cordova und Xamarin eignen sich hingegen nur schlecht für die Umsetzung von Videoaufzeichnung.
Nicht nur die komplett fehlende Einstellbarkeit der Parameter und die fehlende nahtlose Integration der Videoaufzeichnung, sondern auch mehr als viermal langsamere Startzeiten, schränken die Nutzbarkeit stark ein.
Soll die Videoaufzeichnung ein zentrales Merkmal einer App darstellen, ist die Nutzung von Xamarin oder Cordova mit Ionic nicht zu empfehlen.
In anderen Fällen ist die Nutzung nach einer genauen Analyse der Anforderungen und der möglichen Einschränkungen durch die Frameworks denkbar.
Xamarin ist jeweils die besser Alternative, da native Funktionen mit geringerem Aufwand aufgerufen werden können, sodass eine geringere Abhängigkeit von Plugins besteht.


\subsubsection{Gründe für die schlechten Ergebnisse von Ionic mit Cordova und Xamarin}
Die Cross-Plattform Frameworks Cordova und Xamarin sind seit 2011 verfügbar und damit einige Jahre älter als die Frameworks Flutter und React Native, welche erst 2015 und 2017 veröffentlicht wurden \cite{Steyer_Cordova,Sharma_Flutter,Xamarin_EOL,ReactNative_Release}.
Demnach wäre es zu erwarten, dass beide Frameworks in einem ausgereiften Zustand sind und bessere oder zumindest vergleichbare Ergebnisse liefern.
Insbesondere sollten geeignete Plugins vorhanden sein, da Entwickler schon länger mit den Frameworks arbeiten und somit auch schon länger Plugins entwickeln können.

Die Ergebnisse der Evaluierung zeigen jedoch, dass die Frameworks Flutter und React Native deutlich bessere Ergebnisse liefern.
Weiterhin wurde im Laufe der Arbeit klar, dass die Architektur der Frameworks zwar einen Einfluss auf die zu erwartende Performance hat.
Jedoch ist die Fähigkeit auf native Funktionen zuzugreifen in allen Frameworks gegeben, sodass kein technischer Grund für die fehlende Verfügbarkeit passender Plugins vorliegen kann.
Technisch sind Plugins in allen untersuchten Frameworks außer Xamarin prinzipiell gleich aufgebaut: Eine native Implementierung der Funktionalität wird über ein Interface in einer anderen Programmiersprache aufgerufen, wobei das Framework die Kommunikation zwischen nativem und plattformunabhängigem Anteil der Anwendung transparent gestaltet.
Damit wäre auch die Anpassung der nativen Implementierung eines Plugins möglich, um es für ein anderes Framework nutzbar zu machen.
Die Open-Source-Lizenzen der verwendeten Plugins erlauben diese Nutzung ebenfalls.

Xamarin bildet jedoch eine Ausnahme, da keine Plugins für den Zugriff auf native Funktionen benötigt werden.
Stattdessen lassen sich alle \acp{API} aus C\# heraus direkt verwenden.
Dabei kann jeweils der volle Funktionsumfang genutzt werden und Einschränkungen durch Plugins werden vermieden.
Außerdem kann so eine zusätzliche Abhängigkeit zu einem Plugin vermieden werden.
Dennoch existieren für Xamarin Plugins in Form von Bibliotheken, welche die nativen \acp{API} in einfach wiederverwendbarer Form abstrahieren.


Da keine technischen Gründe für die fehlende Verfügbarkeit geeigneter Plugins vorliegen, liegen die Gründe vielmehr in der geringen Beliebtheit und Verbreitung der Frameworks.
In der letzten Stack Overflow Developer Survey \cite{Stackoverflow_2022} nutzten 12,64 \% der Befragen Flutter und 12,57 \% React Native.
Gleichzeitig nutzten nur 4,15 \% Cordova und 5,21 \% Xamarin.
Die Angaben zu Ionic sind hier nicht sinnvoll, da die Nutzung von Ionic als UI-Toolkit keine Auswirkungen auf die Verfügbarkeit von Plugins für Cordova hat.
Eine weitere Umfrage zu den genutzten Cross-Plattform Frameworks von Statista \cite{Statista_UsedCrossPlatformFrameworks} zeigt, dass Flutter und React Native 2021 von 42 \% und 38 \% der Befragten genutzt wurden, während Cordova und Xamarin nur von 16 \% beziehungsweise 11 \% aller Befragten eingesetzt wurden.
Weiterhin gewinnt Flutter in den letzten Jahren an Marktanteil, Cordova und Xamarin hingegen haben seit 2019 große Teile ihres Marktanteils verloren.

Unter Entwicklern beliebte und verbreitete Frameworks haben Vorteile bei der Gewinnung von mitwirkenden Entwicklern.
Durch mehr direkte Beiträge zum Framework werden Fehler zeitnah behoben und neue Funktionen schneller fertiggestellt.
Somit können neue Betriebssystemversionen oder Gerätetypen schneller unterstützt werden, was wiederum die Verbreitung und Beliebtheit des Frameworks positiv beeinflusst.
Gleichzeitig ist durch die größere Zahl der Nutzer die Wahrscheinlichkeit höher, dass andere Nutzer ähnliche Funktionen benötigen und entsprechende Plugins entwickeln.
Damit können Entwickler auf eine größere Zahl von geeigneten Plugins zurückgreifen, was ihnen die Entwicklung erleichtert und vermutlich positiv zur Beliebtheit beiträgt.
Gleichzeitig sorgt ein wachsender Marktanteil für mehr Aufmerksamkeit, wodurch die Verbreitung weiter steigt und das Interesse an der Entwicklung neuer Plugins wächst.
Andererseits führt ein sinkender Marktanteil zu geringerem Interesse an der Entwicklung neuer Plugins, was wiederum die Beliebtheit des Frameworks weiter sinken lässt.

